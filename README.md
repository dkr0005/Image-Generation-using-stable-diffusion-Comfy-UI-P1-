# **Image Generation Using ComfyUI and Stable Diffusion**

🚀 **Internship Project** | **AICTE TechSaksham AI Internship (Microsoft & SAP Initiative)**

This project showcases the power of **Stable Diffusion** combined with **ComfyUI**, a node-based interface that allows for intuitive, flexible, and highly customizable image generation workflows. By leveraging the strengths of these tools, users can create stunning AI-generated visuals from simple text descriptions, fine-tuning results for unique artistic styles.

## **Table of Contents**
- [Introduction](#introduction)
- [Features](#features)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Acknowledgments](#acknowledgments)

---
## **Introduction**
Stable Diffusion is a cutting-edge deep learning model that transforms textual prompts into high-quality images. **ComfyUI** enhances this capability by offering a visual programming environment where users can design complex image generation pipelines using a simple drag-and-drop system. This project integrates these technologies to provide an easy-to-use yet powerful solution for AI-based image generation.

## **Features**
✅ **Node-Based Workflow** – Build custom image generation pipelines effortlessly.
✅ **Text-to-Image Generation** – Convert text prompts into AI-generated visuals using Stable Diffusion.
✅ **Customizable Parameters** – Adjust sampling steps, guidance scales, and more for precise control.
✅ **Modular & Flexible** – Add, remove, or rearrange workflow components with ease.
✅ **Real-Time Feedback** – Preview images as you tweak parameters for optimal results.
✅ **Extensibility** – Integrate additional Python scripts and AI models for advanced functionalities.

## **Requirements**
### **Hardware**
💻 **OS:** Windows 10/11, macOS, or Linux (Recommended for performance).
⚡ **Processor:** Multi-core CPU.
🎮 **GPU:** NVIDIA (8GB+ VRAM recommended) / AMD GPUs require additional setup.
🛠️ **Memory:** 16GB RAM minimum (32GB+ recommended).
📂 **Storage:** SSD with sufficient space for models and outputs.

### **Software**
- Python **3.8+** (Recommended: 3.10 or 3.11)
- **ComfyUI** (Clone from official GitHub repository)
- **Stable Diffusion Model Checkpoint** (`.ckpt` or `.safetensors` file)
- **Required Python Libraries**

## **Installation**
1. **Install Python** – Ensure Python 3.8+ is installed.
2. **Clone ComfyUI** – Clone the ComfyUI repository to your local system.
3. **Download Stable Diffusion Model** – Acquire a compatible `.ckpt` or `.safetensors` file from Hugging Face or other sources.
4. **Place Model Checkpoint** – Move the downloaded model file to the appropriate directory within ComfyUI.
5. **Create a Virtual Environment** (Recommended) – Set up a virtual environment for dependency management.
6. **Install Dependencies** – Ensure all required Python libraries are installed.
7. **Run ComfyUI** – Launch the application following its documentation.

## **Usage**
1. **Launch ComfyUI** – Start the application following its documentation.
2. **Load Workflow (Optional)** – Import pre-designed workflows for different artistic effects.
3. **Enter Prompt** – Input a text description for the image.
4. **Modify Parameters** – Adjust guidance scales, resolution, and more.
5. **Generate Image** – Run the workflow to create AI-generated visuals.
6. **Save & Share** – Download or further refine the generated image.

## **Acknowledgments**
This project is part of the **AICTE TechSaksham AI Internship**, a joint CSR initiative by **Microsoft & SAP** aimed at empowering students with hands-on experience in AI-driven technologies.

🔗 **Resources:**
- [ComfyUI GitHub](https://github.com/comfyanonymous/ComfyUI)
- [Stable Diffusion Documentation](https://huggingface.co/CompVis/stable-diffusion)
- [Hugging Face Models](https://huggingface.co/)

---
🚀 **Thanks!** 🎨✨

